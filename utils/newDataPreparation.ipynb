{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9INzPcbAUYOK"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x75110838a590>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_val = 420\n",
    "torch.manual_seed(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img, mode, size=(50, 50), cutoff=40, debug=False):\n",
    "    \"\"\"\n",
    "    Apply the specified preprocessing mode to the image.\n",
    "    \"\"\"\n",
    "    if mode == 'grayscale':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    elif mode == 'resize':\n",
    "        return cv2.resize(img, size)\n",
    "    elif mode in ['low_freq', 'high_freq']:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        dft = np.fft.fft2(gray)\n",
    "        dft_shift = np.fft.fftshift(dft)\n",
    "\n",
    "        rows, cols = gray.shape\n",
    "        crow, ccol = rows // 2, cols // 2\n",
    "\n",
    "        # Gaussian filter\n",
    "        x, y = np.ogrid[:rows, :cols]\n",
    "        if mode == 'low_freq':\n",
    "            mask = np.exp(-((x - crow)**2 + (y - ccol)**2) / (2.0 * cutoff**2))\n",
    "        elif mode == 'high_freq':\n",
    "            mask = 1 - np.exp(-((x - crow)**2 + (y - ccol)**2) / (2.0 * cutoff**2))\n",
    "\n",
    "        # Apply mask to frequency domain\n",
    "        filtered = dft_shift * mask\n",
    "\n",
    "        # Transform back to the spatial domain\n",
    "        img_back = np.fft.ifft2(np.fft.ifftshift(filtered))\n",
    "        img_back = np.abs(img_back)\n",
    "\n",
    "        # Normalize to 8-bit range\n",
    "        img_back = cv2.normalize(img_back, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        img_back = img_back.astype(np.uint8)\n",
    "\n",
    "        # Debugging: Visualize frequency spectrum\n",
    "        if debug:\n",
    "            magnitude_spectrum = 20 * np.log(np.abs(dft_shift) + 1)\n",
    "            cv2.imshow(f'{mode} Magnitude Spectrum', magnitude_spectrum)\n",
    "            cv2.imshow(f'{mode} Filtered Image', img_back)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        return img_back\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode specified!\")\n",
    "\n",
    "def get_all_files_recursive(directory, extensions=('.jpg', '.png', '.jpeg')):\n",
    "    \"\"\"\n",
    "    Recursively collects all files with the specified extensions from a directory and its subdirectories.\n",
    "    \"\"\"\n",
    "    all_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(extensions):\n",
    "                all_files.append(os.path.join(root, file))\n",
    "    return all_files\n",
    "\n",
    "def preprocess_directory(input_dir, output_dir, mode, size=(50, 50), cutoff=20, subset_fraction=0.1):\n",
    "    \"\"\"\n",
    "    Preprocess a subset of images in a directory (recursively if needed) based on the mode.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get list of all image files recursively\n",
    "    all_files = get_all_files_recursive(input_dir)\n",
    "    if not all_files:\n",
    "        print(f\"No valid files found in '{input_dir}'\")\n",
    "        return 0\n",
    "\n",
    "    # Randomly sample a subset\n",
    "    subset_size = min(len(all_files), max(1, int(len(all_files) * subset_fraction)))  # Ensure valid subset size\n",
    "    subset_files = random.sample(all_files, subset_size)\n",
    "\n",
    "    processed_count = 0\n",
    "    for img_path in subset_files:\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # Preprocess the image\n",
    "        processed_img = preprocess_image(img, mode, size=size, cutoff=cutoff)\n",
    "\n",
    "        # Save the processed image to the output directory (keep relative path structure)\n",
    "        relative_path = os.path.relpath(img_path, input_dir)\n",
    "        output_path = os.path.join(output_dir, relative_path)\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        cv2.imwrite(output_path, processed_img)\n",
    "        processed_count += 1\n",
    "\n",
    "    print(f\"Processed {processed_count}/{len(all_files)} images in '{input_dir}'\")\n",
    "    return processed_count\n",
    "\n",
    "\n",
    "def prepare_dataset(base_dir, output_base_dir, mode, size=(50, 50), cutoff=20, subset_fraction=0.1):\n",
    "    \"\"\"\n",
    "    Preprocess 10% of the dataset in a specific mode.\n",
    "    \"\"\"\n",
    "    total_processed = 0\n",
    "\n",
    "    # Process \"generated\" (fake) images\n",
    "    print(f\"Processing 'generated' images for mode: {mode}\")\n",
    "    total_processed += preprocess_directory(\n",
    "        os.path.join(base_dir, 'generated'),\n",
    "        os.path.join(output_base_dir, f'{mode}_generated'),\n",
    "        mode, size=size, cutoff=cutoff, subset_fraction=subset_fraction\n",
    "    )\n",
    "\n",
    "    # Process \"real\" images\n",
    "    print(f\"Processing 'real' images for mode: {mode}\")\n",
    "    total_processed += preprocess_directory(\n",
    "        os.path.join(base_dir, 'real'),\n",
    "        os.path.join(output_base_dir, f'{mode}_real'),\n",
    "        mode, size=size, cutoff=cutoff, subset_fraction=subset_fraction\n",
    "    )\n",
    "\n",
    "    print(f\"Total images processed for mode '{mode}': {total_processed}\")\n",
    "    return total_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 'generated' images for mode: high_freq\n",
      "No valid files found in '../data/deepfake/original/generated'\n",
      "Processing 'real' images for mode: high_freq\n",
      "No valid files found in '../data/deepfake/original/real'\n",
      "Total images processed for mode 'high_freq': 0\n",
      "Finished processing. Total images processed: 0\n"
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "base_data_dir = '../../data/artifact'  # Replace with your dataset directory\n",
    "output_data_dir = '../../data/processed'  # Directory to save processed data\n",
    "mode = 'high_freq'  # Change to 'grayscale','resize', 'low_freq', or 'high_freq' as needed\n",
    "\n",
    "# Process 10% of the dataset in the specified mode\n",
    "total_images_processed = prepare_dataset(base_data_dir, output_data_dir, mode, subset_fraction=0.1)\n",
    "print(f\"Finished processing. Total images processed: {total_images_processed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved at ../../data/artifact/image_labels.csv\n"
     ]
    }
   ],
   "source": [
    "data = [] \n",
    "base_data_dir = '../../data/artifact'\n",
    "fake_dir = os.path.join(base_data_dir, 'generated')  # Fake artworks directory\n",
    "real_dir = os.path.join(base_data_dir, 'real')  # Real artworks directory\n",
    "\n",
    "# Iterate over the fake artworks and add their paths and labels to the list\n",
    "for dirpath, dirnames, filenames in os.walk(fake_dir):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".jpg\"): # only consider jpg files\n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            data.append((filepath, \"0\"))\n",
    "\n",
    "\n",
    "# Iterate over the real artworks and add their paths and labels to the list\n",
    "for dirpath, dirnames, filenames in os.walk(real_dir):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            data.append((filepath, \"1\"))  # Label 1 for real artworks\n",
    "\n",
    "# Convert the list \"data\" to a pandas dataframe\n",
    "df = pd.DataFrame(data, columns=[\"path\", \"label\"])\n",
    "\n",
    "dataset = df\n",
    "dataset['label'] = dataset['label'].astype(int)\n",
    "dataset\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "csv_output_path = os.path.join(base_data_dir, \"image_labels.csv\")\n",
    "df.to_csv(csv_output_path, index=False)\n",
    "print(f\"CSV file saved at {csv_output_path}\")\n",
    "\n",
    "\n",
    "train_val_data, test = train_test_split(dataset.values, test_size=0.1, random_state=seed_val)\n",
    "test_links = pd.DataFrame(test, columns = dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8816/8816 test images.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8816"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_test_set(test_links, output_dir, mode, size=(50, 50), cutoff=20):\n",
    "    \"\"\"\n",
    "    Preprocess all images listed in test_links and save to output directory.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    processed_count = 0\n",
    "\n",
    "    for idx, row in test_links.iterrows():\n",
    "        img_path = row[\"path\"]\n",
    "        label = row[\"label\"]\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Unable to read image {img_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Preprocess the image\n",
    "        processed_img = preprocess_image(img, mode, size=size, cutoff=cutoff)\n",
    "\n",
    "        # Create a subfolder based on the label for organized storage\n",
    "        label_dir = os.path.join(output_dir, str(label))\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "        # Save the processed image\n",
    "        output_path = os.path.join(label_dir, os.path.basename(img_path))\n",
    "        cv2.imwrite(output_path, img)\n",
    "        processed_count += 1\n",
    "\n",
    "    print(f\"Processed {processed_count}/{len(test_links)} test images.\")\n",
    "    return processed_count\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "mode = 'resize'  # Example preprocessing mode\n",
    "output_dir = '../../data/artifact/test_set'\n",
    "preprocess_test_set(test_links, output_dir, mode=mode, size=(25, 25), cutoff=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1104/11047 images in '../../data/deepfakeart/original'\n",
      "Finished processing. Total images processed: 1104\n"
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "base_data_dir = '../../data/deepfakeart/original'  # Replace with your dataset directory\n",
    "output_data_dir = '../../data/processed/deepfakeart/low_freq'  # Directory to save processed data\n",
    "mode = 'low_freq'  # Change to 'grayscale','resize', 'low_freq', or 'high_freq' as needed\n",
    "\n",
    "# Process 10% of the dataset in the specified mode\n",
    "total_images_processed = preprocess_directory(base_data_dir, output_data_dir, mode)\n",
    "print(f\"Finished processing. Total images processed: {total_images_processed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
