{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 02:38:06.670411: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-21 02:38:06.687278: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x72962eb30230>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_val = 420\n",
    "torch.manual_seed(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for logging the misclassified images in tensorboard\n",
    "def denormalize_image(tensor, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)):\n",
    "    \"\"\"Denormalizes a tensor image by applying the inverse of the normalization transform.\"\"\"\n",
    "    # Reshape mean and std to match the (C, H, W) shape of the tensor\n",
    "    mean = torch.tensor(mean).view(3, 1, 1).to(tensor.device)  # Match device as well\n",
    "    std = torch.tensor(std).view(3, 1, 1).to(tensor.device)\n",
    "    denormalized = tensor * std + mean\n",
    "    return denormalized.clamp(0, 1)\n",
    "\n",
    "def add_labels_to_image(image, true_label, pred_label):\n",
    "    \"\"\"Add true and predicted labels to the image.\"\"\"\n",
    "    # Convert the image to uint8 if it's in float format\n",
    "    if image.dtype != np.uint8:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "\n",
    "    # Convert from RGB to BGR for OpenCV\n",
    "    bgr_image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Prepare text without brackets\n",
    "    text = f'True: {int(true_label)}, Pred: {int(pred_label)}'\n",
    "    cv2.putText(bgr_image, text, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Convert back to RGB before returning\n",
    "    return cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def log_misclassified_images(misclassified_images, misclassified_preds, misclassified_true, writer):\n",
    "    print(\"Logging misclassified images...\")\n",
    "    print(len(misclassified_images))\n",
    "    labeled_images = []\n",
    "\n",
    "    for i, img in enumerate(misclassified_images):\n",
    "        img = denormalize_image(img)  # Denormalize the image\n",
    "        img_np = img.permute(1, 2, 0).numpy()  # Convert (C, H, W) -> (H, W, C)\n",
    "      \n",
    "\n",
    "        # Ensure the image is in the right format for TensorBoard\n",
    "        if img_np.shape[-1] == 1:  # Check if the image is grayscale\n",
    "            img_np = img_np.squeeze(axis=2)  # Remove the channel dimension if it is 1\n",
    "        elif img_np.shape[0] == 1:  # If the shape is (1, H, W)\n",
    "            img_np = img_np.squeeze(axis=0)  # Remove the batch dimension\n",
    "        img_np = np.clip(img_np, 0, 1)  # Ensure the values are between 0 and 1\n",
    "        img_np = (img_np * 255).astype(np.uint8)     # Scale to 0-255\n",
    "\n",
    "        true_label = misclassified_true[i]\n",
    "        pred_label = misclassified_preds[i]\n",
    "\n",
    "        labeled_image = add_labels_to_image(img_np, true_label, pred_label)\n",
    "        # labeled_image = labeled_image.transpose(2, 0, 1)\n",
    "        labeled_images.append(labeled_image)\n",
    "\n",
    "    # Log image to TensorBoard\n",
    "    writer.add_images(\n",
    "        f'Misclassified',\n",
    "        np.array(labeled_images),\n",
    "        dataformats='NHWC'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_folder(model, folder_path, device='cuda', transform=None, writer=None, true_label=None):\n",
    "    \"\"\"\n",
    "    Apply a trained model to all images in a folder and calculate metrics.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PyTorch model.\n",
    "        folder_path: Path to the folder containing images.\n",
    "        device: Device to run inference on ('cuda' or 'cpu').\n",
    "        transform: Transformations to apply to images.\n",
    "        writer: TensorBoard SummaryWriter for logging.\n",
    "        true_label: Optional, the expected true label (used for calculating metrics).\n",
    "    \n",
    "    Returns:\n",
    "        predictions: List of predicted classes.\n",
    "        metrics: Dictionary with accuracy, recall, precision, F1-score (if true_label is provided).\n",
    "    \"\"\"\n",
    "    # Move model to the appropriate device and set to eval mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    pred_list = []\n",
    "    true_list = []\n",
    "    misclassified_images = []\n",
    "    misclassified_preds = []\n",
    "    misclassified_true = []\n",
    "\n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp')\n",
    "    files = [f for f in os.listdir(folder_path) if f.lower().endswith(valid_extensions)]\n",
    "\n",
    "    print(f\"Processing {len(files)} images in {folder_path}.\")\n",
    "    pbar = tqdm(total=len(files), desc=\"Processing images\")\n",
    "\n",
    "    for idx, file_name in enumerate(files):\n",
    "        img_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Open and preprocess the image\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Ensure 3 channels\n",
    "        if transform:\n",
    "            img = transform(img)\n",
    "        \n",
    "        img_tensor = img.unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "            predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "        pred_list.append(predicted_class)\n",
    "\n",
    "        # Handle true labels and misclassifications\n",
    "        if true_label is not None:\n",
    "            true_list.append(true_label)\n",
    "            if predicted_class != true_label:\n",
    "                misclassified_images.append(img.cpu())\n",
    "                misclassified_preds.append(predicted_class)\n",
    "                misclassified_true.append(true_label)\n",
    "        \n",
    "        # Log to TensorBoard\n",
    "        if writer:\n",
    "            writer.add_scalar(f'Predictions/Probability/Image_{idx}', probabilities.max().item(), idx)\n",
    "            writer.add_text(f'Predictions/Class/Image_{idx}', f\"Image: {file_name}, Predicted: {predicted_class}, True: {true_label}\", idx)\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    # Calculate metrics if true labels are available\n",
    "    metrics = {}\n",
    "    if true_list:\n",
    "        accuracy = 100. * sum(1 for p, t in zip(pred_list, true_list) if p == t) / len(true_list)\n",
    "\n",
    "        metrics = {\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "\n",
    "        # Log metrics to TensorBoard\n",
    "        if writer:\n",
    "            for metric, value in metrics.items():\n",
    "                writer.add_scalar(f'Metrics/{metric}', value)\n",
    "\n",
    "        print(f\"\\nMetrics - {folder_path}\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric.capitalize()}: {value:.2f}%\")\n",
    "\n",
    "        # Log misclassified images if writer is provided\n",
    "        if writer:\n",
    "            log_misclassified_images(misclassified_images[:250], misclassified_preds[:250], misclassified_true[:250], writer)\n",
    "\n",
    "    # Return predictions and metrics\n",
    "    return pred_list, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multiple_folders(model, base_path, folder_list, device='cuda', transform=None, true_labels=None):\n",
    "    \"\"\"\n",
    "    Process multiple folders using the given model and log results.\n",
    "\n",
    "    Args:\n",
    "        model: Trained PyTorch model.\n",
    "        base_path: Base directory containing folders.\n",
    "        folder_list: List of folder names to process.\n",
    "        device: Device to run inference on ('cuda' or 'cpu').\n",
    "        transform: Transformations to apply to images.\n",
    "        true_labels: Dictionary mapping folder names to their true labels.\n",
    "\n",
    "    Returns:\n",
    "        results: Dictionary with folder names as keys and metrics as values.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for folder in folder_list:\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        writer_path = f\"runs/processed/{folder}\"\n",
    "        os.makedirs(writer_path, exist_ok=True)\n",
    "\n",
    "        writer = SummaryWriter(writer_path)\n",
    "\n",
    "        # Get true label for the folder\n",
    "        true_label = true_labels.get(folder, 0)  # Default to 0 if not specified\n",
    "\n",
    "        _, metrics = test_on_folder(\n",
    "            model, folder_path, device=device, transform=transform, writer=writer, true_label=true_label\n",
    "        )\n",
    "        writer.close()\n",
    "\n",
    "        results[folder] = metrics\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log confusion matrix to TensorBoard\n",
    "def log_confusion_matrix(writer, cm, class_names, folder_name, step=0):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title(f'Confusion Matrix: {folder_name}')\n",
    "    # Add the figure to TensorBoard\n",
    "    writer.add_figure(f'Confusion Matrix/{folder_name}', fig, global_step=step)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path, model, transform, device, folder_name, writer):\n",
    "    # Use ImageFolder to load the data\n",
    "    dataset = datasets.ImageFolder(root=folder_path, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    # Move model to the appropriate device\n",
    "    model = model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Compute metrics\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='binary')\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    # Log confusion matrix to TensorBoard\n",
    "    log_confusion_matrix(writer, cm, dataset.classes, folder_name)\n",
    "\n",
    "    accuracy = np.sum(all_predictions == all_labels) / len(all_labels)\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"confusion_matrix\": cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1820 images in ../data/deepfakeart/generated/adversarial/FGSM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 1820/1820 [00:58<00:00, 31.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics - ../data/deepfakeart/generated/adversarial/FGSM\n",
      "Accuracy: 57.58%\n",
      "Logging misclassified images...\n",
      "250\n",
      "Results for FGSM:\n",
      "Accuracy: 57.5824\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'precision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 73\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'precision'"
     ]
    }
   ],
   "source": [
    "# Base directory and folders to process\n",
    "writer = SummaryWriter(log_dir='runs/deepfake')\n",
    "base_path = \"../data/deepfakeart/generated/adversarial\"\n",
    "folders = [\"FGSM\"] \n",
    "true_labels = {\n",
    "    \"grayscale_generated\": 0,\n",
    "    \"grayscale_real\": 1,\n",
    "    \"high_freq_generated\": 0,\n",
    "    \"high_freq_real\": 1,\n",
    "    \"low_freq_generated\": 0,\n",
    "    \"low_freq_real\": 1,\n",
    "    \"resized_generated\": 0,\n",
    "    \"resized_real\": 1,\n",
    "    \"deepfakeart\": 1,\n",
    "    \"low_freq\": 1,\n",
    "    \"high_freq\": 1,\n",
    "    \"original\": 1,\n",
    "    \"adversarial\": 1,\n",
    "    \"cutmix\": 1,\n",
    "    \"inpainting\": 1,\n",
    "    \"style_transfer\": 1,\n",
    "    \"APGD\": 1,\n",
    "    \"FGSM\": 1,\n",
    "    \"PGD\": 1,\n",
    "    \"resizedto25px/resize_generated\": 0,\n",
    "    \"resizedto25px/resize_real\":1,\n",
    "    \"testdata_resized25px/0\": 0,\n",
    "    \"testdata_resized25px/1\": 1\n",
    "}\n",
    "\n",
    "# Load the trained model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = timm.create_model('convnext_base', pretrained=False, num_classes=2)\n",
    "model_path = 'saved_models/convnext_model/RealArt_vs_FakeArt_convnext_base.pt'\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "test_data_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: transforms.functional.pad(\n",
    "        img, \n",
    "        (\n",
    "            (max(img.size) - img.size[0]) // 2,  # Padding on the left\n",
    "            (max(img.size) - img.size[1]) // 2,  # Padding on the top\n",
    "            (max(img.size) - img.size[0] + 1) // 2,  # Padding on the right\n",
    "            (max(img.size) - img.size[1] + 1) // 2   # Padding on the bottom\n",
    "        ), \n",
    "            fill=0)),  # Pad image to square (by adding black padding)\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# # Process all folders\n",
    "results = process_multiple_folders(\n",
    "    model, base_path, folders, device=device, transform=test_data_transforms, true_labels=true_labels\n",
    ")\n",
    "\n",
    "\n",
    "# # Iterate through all folders and process data\n",
    "# results = {}\n",
    "# for folder in folders:\n",
    "#     folder_path = os.path.join(base_path, folder)\n",
    "#     if os.path.exists(folder_path):\n",
    "#         metrics = process_folder(folder_path, model, test_data_transforms, device, folder)\n",
    "#         results[folder] = metrics\n",
    "#     else:\n",
    "#         print(f\"Folder {folder_path} does not exist!\")\n",
    "\n",
    "# Print summary of results\n",
    "for folder, metrics in results.items():\n",
    "    print(f\"Results for {folder}:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1_score']:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['confusion_matrix']}\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
